{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Can a model be written to win FiveThirtyEight's NFL prediction game?\n",
    "\n",
    "The National Football League is one of the most watched sports leagues in the world, second to perhaps only Soccer. The Super Bowl (the championship of American Football) is the most watched sporting event year after year. Because of it's popularity, fans flock to fantasy football as well as gambling to further enhance their viewing experience. A popular sports and politics journalism site, FiveThrityEight, uses data driven approaches to try and forecast the outcome of each game. In addition, they allow their fans to take part and see how their predictions would stack up against FiveThirtyEight's model.\n",
    "\n",
    "The way the game works is by assigning probabilities rather than just winners and losers. The system FiveThirtyEight uses scores each player's probability predictions. A correct prediction can net the player up to +25 points whereas an incorrect prediction can cost the player -75 points. The amount of points is determine by the Brier Score (https://en.wikipedia.org/wiki/Brier_score), but the essential thing to understand is that the system punishes aggresive votes for being wrong (i.e. if I say the probability of the home team winning is 91% and they lose, I would lose the majority of the roughly -58 points)and also punishes probability predictions that are too conservative (i.e. if I say the probability of the home team winning is 76% and they do, I would only gain 19 points). FiveThirtyEight's own model is based off of the Elo rating system (https://en.wikipedia.org/wiki/Elo_rating_system) and tends to be provide more conservative predictions. The full rules of the game can be found at (https://fivethirtyeight.com/features/how-to-play-our-nfl-predictions-game/) and a description of FiveThirtyEight's model is at (https://fivethirtyeight.com/features/introducing-nfl-elo-ratings/)\n",
    "\n",
    "This series of notebooks will go through our process of creating a model to try and outperform FiveThirtyEight's own Elo model. In order to do this, we're going to incorporate NFL betting data, weather data, and FiveThrityEight's own Elo data. We'll walk through the process of data cleaning and preparation, do some light univariate and multivariate analysis, and then build a decision tree model. These notebooks will walk through each of those steps to ensure that everything is repeatable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Data Loading & Preparation\n",
    "\n",
    "The first step will be loading the data. We have chosen to include the CSVs from our various sources in the same directory as our Jupyter notebooks. You may want to instead read the files directly from a hyperlink. If so, you'll need to change the second cell below.\n",
    "\n",
    "Each cell should be run in order once the data has been loaded. Each code segment is commented so that it explains what it does. Any major code segments will have a markdown cell explaining it further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: ggplot2\n",
      "Loading required package: RColorBrewer\n",
      "Loading required package: ggthemes\n",
      "Loading required package: gridExtra\n",
      "Loading required package: lubridate\n",
      "\n",
      "Attaching package: ‘lubridate’\n",
      "\n",
      "The following object is masked from ‘package:base’:\n",
      "\n",
      "    date\n",
      "\n",
      "Loading required package: tidyr\n",
      "Loading required package: plyr\n",
      "\n",
      "Attaching package: ‘plyr’\n",
      "\n",
      "The following object is masked from ‘package:lubridate’:\n",
      "\n",
      "    here\n",
      "\n",
      "Loading required package: dplyr\n",
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "The following objects are masked from ‘package:plyr’:\n",
      "\n",
      "    arrange, count, desc, failwith, id, mutate, rename, summarise,\n",
      "    summarize\n",
      "\n",
      "The following objects are masked from ‘package:lubridate’:\n",
      "\n",
      "    intersect, setdiff, union\n",
      "\n",
      "The following object is masked from ‘package:gridExtra’:\n",
      "\n",
      "    combine\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "Loading required package: reshape2\n",
      "\n",
      "Attaching package: ‘reshape2’\n",
      "\n",
      "The following object is masked from ‘package:tidyr’:\n",
      "\n",
      "    smiths\n",
      "\n",
      "Loading required package: dummies\n",
      "dummies-1.5.6 provided by Decision Patterns\n",
      "\n",
      "Loading required package: caTools\n",
      "Loading required package: rpart\n",
      "Loading required package: rpart.plot\n",
      "Loading required package: rattle\n",
      "Rattle: A free graphical interface for data science with R.\n",
      "Version 5.2.0 Copyright (c) 2006-2018 Togaware Pty Ltd.\n",
      "Type 'rattle()' to shake, rattle, and roll your data.\n"
     ]
    }
   ],
   "source": [
    "#short list of packages we'll be using\n",
    "packages <- c(\"ggplot2\",\"RColorBrewer\",\"ggthemes\",\"gridExtra\",\"lubridate\",\"tidyr\",\"plyr\",\"dplyr\",\"reshape2\",\"dummies\",\"caTools\",\"rpart\",\"rpart.plot\",\"rattle\")\n",
    "\n",
    "#install packages if they aren't already installed\n",
    "#then load the packages\n",
    "for (package in packages){\n",
    "    if(!require(package,character.only=TRUE)) install.packages(package,character.only=TRUE)\n",
    "    library(package,character.only=TRUE,quietly=TRUE)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data sets\n",
    "\n",
    "#sourced from:\n",
    "#https://github.com/fivethirtyeight/nfl-elo-game\n",
    "nfl_elo_df <- read.csv(\"nfl_games.csv\", as.is = TRUE, header = TRUE)\n",
    "\n",
    "#sourced from: \n",
    "#https://www.kaggle.com/tobycrabtree/nfl-scores-and-betting-data\n",
    "nfl_teams_df <- read.csv(\"nfl_teams.csv\", as.is = TRUE, header = TRUE)\n",
    "nfl_stadiums_df <- read.csv(\"nfl_stadiums.csv\", as.is = TRUE, header = TRUE)\n",
    "nfl_games_df <- read.csv(\"spreadspoke_scores.csv\", as.is = TRUE, header = TRUE)\n",
    "\n",
    "#we chose to download the data into the same folder as our notebooks, but you may want to change that and read directly\n",
    "#from a web link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'data.frame':\t12411 obs. of  11 variables:\n",
      " $ schedule_date     : Date, format: \"1966-09-02\" \"1966-09-03\" ...\n",
      " $ schedule_season   : int  1966 1966 1966 1966 1966 1966 1966 1966 1966 1966 ...\n",
      " $ home_team_id      : chr  \"MIA\" \"TEN\" \"LAC\" \"MIA\" ...\n",
      " $ away_team_id      : chr  \"OAK\" \"DEN\" \"BUF\" \"NYJ\" ...\n",
      " $ home_score        : int  14 45 27 14 24 31 24 14 20 14 ...\n",
      " $ away_score        : int  23 7 7 19 3 0 0 19 42 3 ...\n",
      " $ team_favorite_id  : chr  \"\" \"\" \"\" \"\" ...\n",
      " $ spread_favorite   : num  NA NA NA NA NA NA NA NA NA NA ...\n",
      " $ home_team_elo     : num  1300 1377 1543 1288 1618 ...\n",
      " $ away_team_elo     : num  1523 1383 1619 1454 1587 ...\n",
      " $ home_team_win_prob: num  0.287 0.585 0.484 0.359 0.635 ...\n"
     ]
    }
   ],
   "source": [
    "#some data prep\n",
    "\n",
    "#transform dates so we can join the data easier\n",
    "nfl_games_df$schedule_date <- as.Date(parse_date_time(nfl_games_df$schedule_date, \"mdy\"))\n",
    "nfl_elo_df$date <- as.Date(parse_date_time(nfl_elo_df$date, \"ymd\"))\n",
    "\n",
    "#join team data to games data\n",
    "#this helps us remap some of the IDs and such so that all teams are identified the same way\n",
    "nfl_df <- left_join(nfl_games_df,nfl_teams_df,by=c(\"team_home\"=\"team_name\"))\n",
    "nfl_df <- left_join(nfl_df, nfl_teams_df, by = c(\"team_away\" = \"team_name\"))\n",
    "\n",
    "#rename variables to home and away\n",
    "#after the join we get an x and y for matching variable names from the above joins\n",
    "#this just remaps things so we can \n",
    "names(nfl_df)[names(nfl_df) == 'team_id.x'] <- 'home_team_id'\n",
    "names(nfl_df)[names(nfl_df) == 'team_id.y'] <- 'away_team_id'\n",
    "names(nfl_df)[names(nfl_df) == 'team_conference.x'] <- 'home_team_conference'\n",
    "names(nfl_df)[names(nfl_df) == 'team_division.x'] <- 'home_team_division'\n",
    "names(nfl_df)[names(nfl_df) == 'team_conference.y'] <- 'away_team_conference'\n",
    "names(nfl_df)[names(nfl_df) == 'team_division.y'] <- 'away_team_division'\n",
    "names(nfl_df)[names(nfl_df) == 'team_home'] <- 'home_team'\n",
    "names(nfl_df)[names(nfl_df) == 'score_home'] <- 'home_score'\n",
    "names(nfl_df)[names(nfl_df) == 'score_away'] <- 'away_score'\n",
    "names(nfl_df)[names(nfl_df) == 'team_away'] <- 'away_team'\n",
    "\n",
    "#join elo data to joined data\n",
    "#the elo data and betting data has no common ID so we join on a few columns\n",
    "nfl_df <- left_join(nfl_df, nfl_elo_df, by = c(\"schedule_date\" = \"date\", \"home_team_id\" = \"team1\", \"away_team_id\" = \"team2\"))\n",
    "\n",
    "#rename the elo columns to be more descriptive\n",
    "names(nfl_df)[names(nfl_df) == 'elo1'] <- 'home_team_elo'\n",
    "names(nfl_df)[names(nfl_df) == 'elo2'] <- 'away_team_elo'\n",
    "names(nfl_df)[names(nfl_df) == 'elo_prob1'] <- 'home_team_win_prob'\n",
    "\n",
    "#create even smaller dataframe in order to evaluate ELO and Spread effectiveness\n",
    "nfl_df_filtered <- nfl_df[,c('schedule_date',\n",
    "                             'schedule_season',\n",
    "                             'home_team_id',\n",
    "                             'away_team_id',\n",
    "                             'home_score',\n",
    "                             'away_score',\n",
    "                             'team_favorite_id',\n",
    "                             'spread_favorite',\n",
    "                             'home_team_elo',\n",
    "                             'away_team_elo',\n",
    "                             'home_team_win_prob'\n",
    "                            )]\n",
    "\n",
    "#looking at the structure of our final dataframe\n",
    "str(nfl_df_filtered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning\n",
    "\n",
    "Now that the data has been loaded variables selected and renamed, we can start cleaning our data. There will be several steps we'll need to take in order to ensure that our data is in the right format for our model. Firstly, we'll need to look at how much data we have an how much is incomplete.\n",
    "\n",
    "### Addressing NULL values\n",
    "\n",
    "Since are data comes from a few different sources (especially the Kaggle data) there are several nulls within our vairables. We can run a quick check on our filtered down dataset to see how many we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Total NULLs in each column\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>schedule_date</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>schedule_season</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>home_team_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>away_team_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>home_score</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>away_score</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>team_favorite_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>spread_favorite</dt>\n",
       "\t\t<dd>2479</dd>\n",
       "\t<dt>home_team_elo</dt>\n",
       "\t\t<dd>1149</dd>\n",
       "\t<dt>away_team_elo</dt>\n",
       "\t\t<dd>1149</dd>\n",
       "\t<dt>home_team_win_prob</dt>\n",
       "\t\t<dd>1149</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[schedule\\textbackslash{}\\_date] 0\n",
       "\\item[schedule\\textbackslash{}\\_season] 0\n",
       "\\item[home\\textbackslash{}\\_team\\textbackslash{}\\_id] 0\n",
       "\\item[away\\textbackslash{}\\_team\\textbackslash{}\\_id] 0\n",
       "\\item[home\\textbackslash{}\\_score] 0\n",
       "\\item[away\\textbackslash{}\\_score] 0\n",
       "\\item[team\\textbackslash{}\\_favorite\\textbackslash{}\\_id] 0\n",
       "\\item[spread\\textbackslash{}\\_favorite] 2479\n",
       "\\item[home\\textbackslash{}\\_team\\textbackslash{}\\_elo] 1149\n",
       "\\item[away\\textbackslash{}\\_team\\textbackslash{}\\_elo] 1149\n",
       "\\item[home\\textbackslash{}\\_team\\textbackslash{}\\_win\\textbackslash{}\\_prob] 1149\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "schedule_date\n",
       ":   0schedule_season\n",
       ":   0home_team_id\n",
       ":   0away_team_id\n",
       ":   0home_score\n",
       ":   0away_score\n",
       ":   0team_favorite_id\n",
       ":   0spread_favorite\n",
       ":   2479home_team_elo\n",
       ":   1149away_team_elo\n",
       ":   1149home_team_win_prob\n",
       ":   1149\n",
       "\n"
      ],
      "text/plain": [
       "     schedule_date    schedule_season       home_team_id       away_team_id \n",
       "                 0                  0                  0                  0 \n",
       "        home_score         away_score   team_favorite_id    spread_favorite \n",
       "                 0                  0                  0               2479 \n",
       "     home_team_elo      away_team_elo home_team_win_prob \n",
       "              1149               1149               1149 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking nulls\n",
    "print(\"Total NULLs in each column\")\n",
    "colSums(is.na(nfl_df_filtered))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Superbowl Era vs Modern Era \n",
    "\n",
    "One way that we can address this is by filtering the timeframe of our data. Our Kaggle data includes data from 1966 until 2018 whereas our FiveThirtyEight Elo data includes data from 1920 until 2017. Both these data sets cover multiple eras of the NFL during which the game was significantly different. For some background, I'll describe the two most common eras:\n",
    "\n",
    "**The Superbowl Era** is the time after the NFL and AFL (American Football League) merged. These two leagues were both fairly large and merged into one league between 1966 and 1970 with the first post season merger happening in 1971. From 1971 one there were two conferences (the AFC and NFC) and the two best teams from each conference played each other in the Superbowl (hence the name). This era is defined as 1971 to the present.\n",
    "\n",
    "**The Modern Era** is the time after the last major expansion of the NFL. In 2001 the NFL added the Houston Texans to make the league a total of 32 teams. This is also when it realigned so that the teams were arranged in 2 conferences with 4 divisions each. This is the longest period of time that the league has been \"stable\" (not adding or rearrangeing teams). It is defined as 2002 to the present.\n",
    "\n",
    "For our analysis we've chosen to use the Modern era to define and filter our data. This will help us remove some of our null values on top of being the most consistent era of play. Most games in the modern era resemble each other in  terms of how the game is played and what players are playing it (which can affect Vegas betting). It will be easier for any model we build as there will, hopefully, be less noise in our data.\n",
    "\n",
    "We encourage you to take the data and filter it based on your own assumptions though!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Total NULLs in each column for Modern Era data\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>schedule_date</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>schedule_season</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>home_team_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>away_team_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>home_score</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>away_score</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>team_favorite_id</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>spread_favorite</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>home_team_elo</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>away_team_elo</dt>\n",
       "\t\t<dd>0</dd>\n",
       "\t<dt>home_team_win_prob</dt>\n",
       "\t\t<dd>0</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[schedule\\textbackslash{}\\_date] 0\n",
       "\\item[schedule\\textbackslash{}\\_season] 0\n",
       "\\item[home\\textbackslash{}\\_team\\textbackslash{}\\_id] 0\n",
       "\\item[away\\textbackslash{}\\_team\\textbackslash{}\\_id] 0\n",
       "\\item[home\\textbackslash{}\\_score] 0\n",
       "\\item[away\\textbackslash{}\\_score] 0\n",
       "\\item[team\\textbackslash{}\\_favorite\\textbackslash{}\\_id] 0\n",
       "\\item[spread\\textbackslash{}\\_favorite] 0\n",
       "\\item[home\\textbackslash{}\\_team\\textbackslash{}\\_elo] 0\n",
       "\\item[away\\textbackslash{}\\_team\\textbackslash{}\\_elo] 0\n",
       "\\item[home\\textbackslash{}\\_team\\textbackslash{}\\_win\\textbackslash{}\\_prob] 0\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "schedule_date\n",
       ":   0schedule_season\n",
       ":   0home_team_id\n",
       ":   0away_team_id\n",
       ":   0home_score\n",
       ":   0away_score\n",
       ":   0team_favorite_id\n",
       ":   0spread_favorite\n",
       ":   0home_team_elo\n",
       ":   0away_team_elo\n",
       ":   0home_team_win_prob\n",
       ":   0\n",
       "\n"
      ],
      "text/plain": [
       "     schedule_date    schedule_season       home_team_id       away_team_id \n",
       "                 0                  0                  0                  0 \n",
       "        home_score         away_score   team_favorite_id    spread_favorite \n",
       "                 0                  0                  0                  0 \n",
       "     home_team_elo      away_team_elo home_team_win_prob \n",
       "                 0                  0                  0 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#filtering data to just the modern era\n",
    "modern_era_df <- nfl_df_filtered %>%\n",
    "    filter(as.numeric(schedule_season) > 2001)\n",
    "\n",
    "#The elo data is missing the 2018 season and so we'll drop those rows\n",
    "modern_era_df <- modern_era_df %>% drop_na(home_team_elo, away_team_elo)\n",
    "\n",
    "#checking nulls\n",
    "print(\"Total NULLs in each column for Modern Era data\")\n",
    "colSums(is.na(modern_era_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Exporting our data\n",
    "\n",
    "Now that we have our data prepared and cleaned, we'll go ahead and generate a CSV so we don't have to do all those joins again during our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to csv that lands in the current working directory\n",
    "write.csv(modern_era_df,file=\"final_output.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
